{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexnet Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from alexnet import AlexNet\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import ConcatDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_augmented = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomAffine(degrees=(-20, 20), translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the entire dataset\n",
    "dataset = ImageFolder('train_imgs', transform=transform)\n",
    "dataset_augmented  = ImageFolder('train_imgs', transform=transform_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for k-fold cross-validation\n",
    "k_folds = 5\n",
    "\n",
    "# Create KFold object to generate k-fold splits\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=1)\n",
    "\n",
    "# Create empty lists to store the accuracies for each fold\n",
    "fold_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "[1,   100] loss: 4.436\n",
      "[1,   200] loss: 4.162\n",
      "[1,   300] loss: 3.858\n",
      "[1,   400] loss: 3.624\n",
      "[1,   500] loss: 3.214\n",
      "[1,   600] loss: 3.028\n",
      "[1,   700] loss: 2.777\n",
      "[2,   100] loss: 2.468\n",
      "[2,   200] loss: 2.342\n",
      "[2,   300] loss: 2.387\n",
      "[2,   400] loss: 2.232\n",
      "[2,   500] loss: 2.064\n",
      "[2,   600] loss: 2.044\n",
      "[2,   700] loss: 1.925\n",
      "[3,   100] loss: 1.797\n",
      "[3,   200] loss: 1.775\n",
      "[3,   300] loss: 1.752\n",
      "[3,   400] loss: 1.723\n",
      "[3,   500] loss: 1.690\n",
      "[3,   600] loss: 1.656\n",
      "[3,   700] loss: 1.634\n",
      "[4,   100] loss: 1.512\n",
      "[4,   200] loss: 1.559\n",
      "[4,   300] loss: 1.488\n",
      "[4,   400] loss: 1.454\n",
      "[4,   500] loss: 1.464\n",
      "[4,   600] loss: 1.416\n",
      "[4,   700] loss: 1.419\n",
      "[5,   100] loss: 1.339\n",
      "[5,   200] loss: 1.270\n",
      "[5,   300] loss: 1.312\n",
      "[5,   400] loss: 1.295\n",
      "[5,   500] loss: 1.294\n",
      "[5,   600] loss: 1.295\n",
      "[5,   700] loss: 1.258\n",
      "[6,   100] loss: 1.182\n",
      "[6,   200] loss: 1.179\n",
      "[6,   300] loss: 1.189\n",
      "[6,   400] loss: 1.161\n",
      "[6,   500] loss: 1.171\n",
      "[6,   600] loss: 1.157\n",
      "[6,   700] loss: 1.149\n",
      "[7,   100] loss: 1.053\n",
      "[7,   200] loss: 1.099\n",
      "[7,   300] loss: 1.074\n",
      "[7,   400] loss: 1.069\n",
      "[7,   500] loss: 1.070\n",
      "[7,   600] loss: 1.078\n",
      "[7,   700] loss: 1.057\n",
      "[8,   100] loss: 0.959\n",
      "[8,   200] loss: 0.987\n",
      "[8,   300] loss: 1.001\n",
      "[8,   400] loss: 0.979\n",
      "[8,   500] loss: 0.994\n",
      "[8,   600] loss: 0.997\n",
      "[8,   700] loss: 0.966\n",
      "[9,   100] loss: 0.921\n",
      "[9,   200] loss: 0.919\n",
      "[9,   300] loss: 0.920\n",
      "[9,   400] loss: 0.922\n",
      "[9,   500] loss: 0.916\n",
      "[9,   600] loss: 0.907\n",
      "[9,   700] loss: 0.959\n",
      "[10,   100] loss: 0.794\n",
      "[10,   200] loss: 0.842\n",
      "[10,   300] loss: 0.836\n",
      "[10,   400] loss: 0.880\n",
      "[10,   500] loss: 0.860\n",
      "[10,   600] loss: 0.867\n",
      "[10,   700] loss: 0.896\n",
      "Accuracy on validation set: 65 %\n",
      "Fold 2/5\n",
      "[1,   100] loss: 0.933\n",
      "[1,   200] loss: 0.951\n",
      "[1,   300] loss: 0.892\n",
      "[1,   400] loss: 0.900\n",
      "[1,   500] loss: 0.913\n",
      "[1,   600] loss: 0.922\n",
      "[1,   700] loss: 0.907\n",
      "[2,   100] loss: 0.805\n",
      "[2,   200] loss: 0.828\n",
      "[2,   300] loss: 0.813\n",
      "[2,   400] loss: 0.817\n",
      "[2,   500] loss: 0.852\n",
      "[2,   600] loss: 0.836\n",
      "[2,   700] loss: 0.849\n",
      "[3,   100] loss: 0.755\n",
      "[3,   200] loss: 0.749\n",
      "[3,   300] loss: 0.782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Darin Tsui\\cogs181\\CNN.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Print statistics\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through the k-fold splits\n",
    "for fold, (train_idxs, val_idxs) in enumerate(kfold.split(dataset)):\n",
    "    print(f'Fold {fold+1}/{k_folds}')\n",
    "\n",
    "    for fold_i, (train_idx_i, val_idx_i) in enumerate(kfold.split(dataset_augmented)):\n",
    "        if fold == fold_i:\n",
    "            train_augmented_idxs = train_idx_i\n",
    "            val_augmented_idxs = val_idx_i\n",
    "            continue\n",
    "    \n",
    "    # Create data loaders for training and validation sets\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_idxs)\n",
    "    train_augmented_dataset = torch.utils.data.Subset(dataset_augmented, train_augmented_idxs)\n",
    "    train_dataset = ConcatDataset([train_dataset, train_augmented_dataset])\n",
    "\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_idxs)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Get the inputs and labels\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # Print every 100 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set: %d %%' % (100 * correct / total))\n",
    "    # Store the loss and accuracy for this fold\n",
    "    fold_accuracies.append(100 * correct / total)\n",
    "\n",
    "# Print the mean and standard deviation of the accuracies for all folds\n",
    "print(f'Mean Accuracy: {np.mean(fold_accuracies):.4f}, Std Accuracy: {np.std(fold_accuracies):.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying Learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "dataset = ImageFolder('train_imgs', transform=transform)\n",
    "\n",
    "# Define the percentage split between training and testing data\n",
    "train_pct = 0.8\n",
    "test_pct = 1 - train_pct\n",
    "\n",
    "# Split the dataset into training and testing sets based on the percentage split\n",
    "num_train = int(train_pct * len(dataset))\n",
    "num_test = len(dataset) - num_train\n",
    "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "\n",
    "# Create data loaders to load the data in batches during training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Save variable loss \n",
    "loss_001 = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_001.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 0.1: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.412\n",
      "[1,   200] loss: 4.200\n",
      "[1,   300] loss: 3.999\n",
      "Accuracy on validation set with lr 0.01: 22 %\n",
      "[2,   100] loss: 3.039\n",
      "[2,   200] loss: 2.733\n",
      "[2,   300] loss: 2.497\n",
      "Accuracy on validation set with lr 0.01: 34 %\n",
      "[3,   100] loss: 2.255\n",
      "[3,   200] loss: 2.091\n",
      "[3,   300] loss: 2.086\n",
      "Accuracy on validation set with lr 0.01: 46 %\n",
      "[4,   100] loss: 1.870\n",
      "[4,   200] loss: 1.821\n",
      "[4,   300] loss: 1.768\n",
      "Accuracy on validation set with lr 0.01: 50 %\n",
      "[5,   100] loss: 1.599\n",
      "[5,   200] loss: 1.627\n",
      "[5,   300] loss: 1.578\n",
      "Accuracy on validation set with lr 0.01: 53 %\n",
      "[6,   100] loss: 1.448\n",
      "[6,   200] loss: 1.427\n",
      "[6,   300] loss: 1.438\n",
      "Accuracy on validation set with lr 0.01: 56 %\n",
      "[7,   100] loss: 1.288\n",
      "[7,   200] loss: 1.301\n",
      "[7,   300] loss: 1.280\n",
      "Accuracy on validation set with lr 0.01: 57 %\n",
      "[8,   100] loss: 1.178\n",
      "[8,   200] loss: 1.169\n",
      "[8,   300] loss: 1.181\n",
      "Accuracy on validation set with lr 0.01: 59 %\n",
      "[9,   100] loss: 1.069\n",
      "[9,   200] loss: 1.077\n",
      "[9,   300] loss: 1.115\n",
      "Accuracy on validation set with lr 0.01: 60 %\n",
      "[10,   100] loss: 0.960\n",
      "[10,   200] loss: 0.971\n",
      "[10,   300] loss: 1.014\n",
      "Accuracy on validation set with lr 0.01: 60 %\n"
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Save variable loss \n",
    "loss_01 = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_01.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 0.01: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.787\n",
      "[1,   200] loss: 4.550\n",
      "[1,   300] loss: 4.188\n",
      "Accuracy on validation set with lr 0.001: 7 %\n",
      "[2,   100] loss: 4.177\n",
      "[2,   200] loss: 4.180\n",
      "[2,   300] loss: 4.152\n",
      "Accuracy on validation set with lr 0.001: 9 %\n",
      "[3,   100] loss: 4.092\n",
      "[3,   200] loss: 3.947\n",
      "[3,   300] loss: 3.873\n",
      "Accuracy on validation set with lr 0.001: 13 %\n",
      "[4,   100] loss: 3.680\n",
      "[4,   200] loss: 3.538\n",
      "[4,   300] loss: 3.317\n",
      "Accuracy on validation set with lr 0.001: 22 %\n",
      "[5,   100] loss: 3.075\n",
      "[5,   200] loss: 2.931\n",
      "[5,   300] loss: 2.815\n",
      "Accuracy on validation set with lr 0.001: 30 %\n",
      "[6,   100] loss: 2.647\n",
      "[6,   200] loss: 2.514\n",
      "[6,   300] loss: 2.468\n",
      "Accuracy on validation set with lr 0.001: 35 %\n",
      "[7,   100] loss: 2.321\n",
      "[7,   200] loss: 2.291\n",
      "[7,   300] loss: 2.263\n",
      "Accuracy on validation set with lr 0.001: 41 %\n",
      "[8,   100] loss: 2.150\n",
      "[8,   200] loss: 2.132\n",
      "[8,   300] loss: 2.103\n",
      "Accuracy on validation set with lr 0.001: 43 %\n",
      "[9,   100] loss: 2.009\n",
      "[9,   200] loss: 2.005\n",
      "[9,   300] loss: 1.970\n",
      "Accuracy on validation set with lr 0.001: 46 %\n",
      "[10,   100] loss: 1.871\n",
      "[10,   200] loss: 1.903\n",
      "[10,   300] loss: 1.854\n",
      "Accuracy on validation set with lr 0.001: 47 %\n"
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Save variable loss \n",
    "loss_001 = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_001.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 0.001: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.795\n",
      "[1,   200] loss: 4.792\n",
      "[1,   300] loss: 4.789\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[2,   100] loss: 4.783\n",
      "[2,   200] loss: 4.778\n",
      "[2,   300] loss: 4.772\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[3,   100] loss: 4.748\n",
      "[3,   200] loss: 4.706\n",
      "[3,   300] loss: 4.477\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[4,   100] loss: 4.209\n",
      "[4,   200] loss: 4.187\n",
      "[4,   300] loss: 4.192\n",
      "Accuracy on validation set with lr 1e-4: 7 %\n",
      "[5,   100] loss: 4.169\n",
      "[5,   200] loss: 4.182\n",
      "[5,   300] loss: 4.168\n",
      "Accuracy on validation set with lr 1e-4: 7 %\n",
      "[6,   100] loss: 4.161\n",
      "[6,   200] loss: 4.166\n",
      "[6,   300] loss: 4.164\n",
      "Accuracy on validation set with lr 1e-4: 8 %\n",
      "[7,   100] loss: 4.171\n",
      "[7,   200] loss: 4.144\n",
      "[7,   300] loss: 4.160\n",
      "Accuracy on validation set with lr 1e-4: 8 %\n",
      "[8,   100] loss: 4.153\n",
      "[8,   200] loss: 4.157\n",
      "[8,   300] loss: 4.160\n",
      "Accuracy on validation set with lr 1e-4: 9 %\n",
      "[9,   100] loss: 4.140\n",
      "[9,   200] loss: 4.143\n",
      "[9,   300] loss: 4.161\n",
      "Accuracy on validation set with lr 1e-4: 9 %\n",
      "[10,   100] loss: 4.145\n",
      "[10,   200] loss: 4.126\n",
      "[10,   300] loss: 4.151\n",
      "Accuracy on validation set with lr 1e-4: 9 %\n"
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "# Save variable loss \n",
    "loss_1e4 = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_1e4.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 1e-4: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 70810.503\n",
      "[1,   200] loss: 5.233\n",
      "[1,   300] loss: 4.617\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[2,   100] loss: 4.846\n",
      "[2,   200] loss: 32894.161\n",
      "[2,   300] loss: 95.568\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[3,   100] loss: 105.875\n",
      "[3,   200] loss: 4.562\n",
      "[3,   300] loss: 4.322\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[4,   100] loss: 4.152\n",
      "[4,   200] loss: 4.329\n",
      "[4,   300] loss: 4.166\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[5,   100] loss: 4.162\n",
      "[5,   200] loss: 35.262\n",
      "[5,   300] loss: 27.647\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[6,   100] loss: 4.315\n",
      "[6,   200] loss: 4.754\n",
      "[6,   300] loss: 4.961\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[7,   100] loss: 4.153\n",
      "[7,   200] loss: 4.497\n",
      "[7,   300] loss: 4.210\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[8,   100] loss: 4.181\n",
      "[8,   200] loss: 4.482\n",
      "[8,   300] loss: 4.309\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[9,   100] loss: 5.846\n",
      "[9,   200] loss: 4.243\n",
      "[9,   300] loss: 4.630\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n",
      "[10,   100] loss: 4.186\n",
      "[10,   200] loss: 4.321\n",
      "[10,   300] loss: 4.794\n",
      "Accuracy on validation set with lr 1e-4: 6 %\n"
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Save variable loss \n",
    "loss_adam = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_adam.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 1e-4: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.375\n",
      "[1,   200] loss: 4.076\n",
      "[1,   300] loss: 3.510\n",
      "Accuracy on validation set with lr 0.01: 27 %\n",
      "[2,   100] loss: 2.808\n",
      "[2,   200] loss: 2.591\n",
      "[2,   300] loss: 2.321\n",
      "Accuracy on validation set with lr 0.01: 38 %\n",
      "[3,   100] loss: 2.080\n",
      "[3,   200] loss: 1.935\n",
      "[3,   300] loss: 1.871\n",
      "Accuracy on validation set with lr 0.01: 49 %\n",
      "[4,   100] loss: 1.709\n",
      "[4,   200] loss: 1.623\n",
      "[4,   300] loss: 1.622\n",
      "Accuracy on validation set with lr 0.01: 53 %\n",
      "[5,   100] loss: 1.473\n",
      "[5,   200] loss: 1.438\n",
      "[5,   300] loss: 1.448\n",
      "Accuracy on validation set with lr 0.01: 56 %\n",
      "[6,   100] loss: 1.273\n",
      "[6,   200] loss: 1.290\n",
      "[6,   300] loss: 1.283\n",
      "Accuracy on validation set with lr 0.01: 58 %\n",
      "[7,   100] loss: 1.127\n",
      "[7,   200] loss: 1.199\n",
      "[7,   300] loss: 1.194\n",
      "Accuracy on validation set with lr 0.01: 59 %\n",
      "[8,   100] loss: 1.112\n",
      "[8,   200] loss: 1.102\n",
      "[8,   300] loss: 1.085\n",
      "Accuracy on validation set with lr 0.01: 60 %\n",
      "[9,   100] loss: 0.965\n",
      "[9,   200] loss: 0.971\n",
      "[9,   300] loss: 0.997\n",
      "Accuracy on validation set with lr 0.01: 61 %\n",
      "[10,   100] loss: 0.837\n",
      "[10,   200] loss: 0.928\n",
      "[10,   300] loss: 0.936\n",
      "Accuracy on validation set with lr 0.01: 61 %\n"
     ]
    }
   ],
   "source": [
    "from alexnet_leaky import AlexNet_leaky\n",
    "\n",
    "# Define the AlexNet model\n",
    "model = AlexNet_leaky(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Save variable loss \n",
    "loss_leaky = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_leaky.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr 0.01: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAM with Lr 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.218\n",
      "[1,   200] loss: 3.667\n",
      "[1,   300] loss: 3.291\n",
      "Accuracy on validation set with lr .001: 30 %\n",
      "[2,   100] loss: 2.565\n",
      "[2,   200] loss: 2.349\n",
      "[2,   300] loss: 2.197\n",
      "Accuracy on validation set with lr .001: 42 %\n",
      "[3,   100] loss: 1.944\n",
      "[3,   200] loss: 1.913\n",
      "[3,   300] loss: 1.910\n",
      "Accuracy on validation set with lr .001: 31 %\n",
      "[4,   100] loss: 1.788\n",
      "[4,   200] loss: 1.730\n",
      "[4,   300] loss: 1.731\n",
      "Accuracy on validation set with lr .001: 49 %\n",
      "[5,   100] loss: 1.659\n",
      "[5,   200] loss: 1.639\n",
      "[5,   300] loss: 1.632\n",
      "Accuracy on validation set with lr .001: 53 %\n",
      "[6,   100] loss: 1.468\n",
      "[6,   200] loss: 1.463\n",
      "[6,   300] loss: 1.491\n",
      "Accuracy on validation set with lr .001: 52 %\n",
      "[7,   100] loss: 1.374\n",
      "[7,   200] loss: 1.399\n",
      "[7,   300] loss: 1.428\n",
      "Accuracy on validation set with lr .001: 54 %\n",
      "[8,   100] loss: 1.285\n",
      "[8,   200] loss: 1.281\n",
      "[8,   300] loss: 1.283\n",
      "Accuracy on validation set with lr .001: 55 %\n",
      "[9,   100] loss: 1.186\n",
      "[9,   200] loss: 1.212\n",
      "[9,   300] loss: 1.235\n",
      "Accuracy on validation set with lr .001: 55 %\n",
      "[10,   100] loss: 1.096\n",
      "[10,   200] loss: 1.127\n",
      "[10,   300] loss: 1.172\n",
      "Accuracy on validation set with lr .001: 52 %\n"
     ]
    }
   ],
   "source": [
    "# Define the AlexNet model\n",
    "model = AlexNet(num_classes=len(dataset.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Save variable loss \n",
    "loss_adam = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        loss_hold = loss.item()\n",
    "        loss_adam.append(loss_hold)\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set with lr .001: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cfmat = confusion_matrix(labels, predicted)\n",
    "sns.heatmap(cfmat, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 21 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on validation set: %d %%' % (100 * correct / total))\n",
    "# Store the loss and accuracy for this fold\n",
    "fold_accuracies.append(100 * correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Darin Tsui\\cogs181\\CNN.ipynb Cell 8\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     images, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Darin Tsui\\cogs181\\alexnet.py:34\u001b[0m, in \u001b[0;36mAlexNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 34\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m     35\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m     36\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m256\u001b[39m \u001b[39m*\u001b[39m \u001b[39m6\u001b[39m \u001b[39m*\u001b[39m \u001b[39m6\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on training set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.545\n",
      "[1,   200] loss: 4.209\n",
      "[1,   300] loss: 4.166\n",
      "[1,   400] loss: 4.058\n",
      "[1,   500] loss: 3.838\n",
      "[1,   600] loss: 3.612\n",
      "[1,   700] loss: 3.326\n",
      "[1,   800] loss: 3.169\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Darin Tsui\\cogs181\\CNN.ipynb Cell 5\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m val_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         images, labels \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Darin%20Tsui/cogs181/CNN.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # Print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 24 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy on validation set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
